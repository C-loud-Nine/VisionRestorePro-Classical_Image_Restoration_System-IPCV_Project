# ğŸ”® VisionRestore Pro

<div align="center">

![VisionRestore Pro Banner](docs/images/banner.png)

**Advanced Image Restoration with Intelligent Degradation-Aware Processing**

[![Python](https://img.shields.io/badge/Python-3.8%2B-blue.svg)](https://www.python.org/)
[![Streamlit](https://img.shields.io/badge/Streamlit-1.28%2B-FF4B4B.svg)](https://streamlit.io/)
[![License](https://img.shields.io/badge/License-MIT-green.svg)](LICENSE)
[![OpenCV](https://img.shields.io/badge/OpenCV-4.8%2B-5C3EE8.svg)](https://opencv.org/)

[Features](#-key-features) â€¢ [Demo](#-demo) â€¢ [Installation](#-installation) â€¢ [Usage](#-usage) â€¢ [Architecture](#-architecture) â€¢ [Performance](#-performance)

</div>

---

## ğŸ“‹ Table of Contents

- [Overview](#-overview)
- [Demo](#-demo)
- [Key Features](#-key-features)
- [Installation](#-installation)
- [Quick Start](#-quick-start)
- [Usage Guide](#-usage-guide)
- [Architecture](#-architecture)
- [Core Algorithms](#-core-algorithms)
- [Performance](#-performance)
- [API Reference](#-api-reference)
- [Contributing](#-contributing)
- [License](#-license)

---

## ğŸŒŸ Overview

**VisionRestore Pro** is a state-of-the-art image restoration application that combines advanced computational photography techniques with an intelligent degradation-aware processing pipeline. Built with Python and Streamlit, it provides professional-grade image restoration capabilities through an intuitive web interface.

### ğŸ¯ What Makes It Special

- **ğŸ¤– Intelligent Processing**: Automatically detects and adapts to different types of image degradation
- **ğŸ¨ Custom Degradation Pipeline**: Create and test custom image degradations for algorithm validation
- **ğŸ“Š Comprehensive Metrics**: Real-time quality assessment with PSNR, SSIM, MSE, and sharpness metrics
- **âš¡ Adaptive Algorithms**: Smart algorithm selection based on degradation severity
- **ğŸ–¥ï¸ Modern UI**: Professional dark-themed interface with intuitive controls

---

## ğŸ¬ Demo

### Application Interface

![VisionRestore Pro Interface](docs/screenshots/main_interface.png)
*Main application interface with tabbed navigation and real-time controls*

### Restoration Results

![Restoration Results](docs/screenshots/restoration_results.png)
*Complete restoration pipeline: Input â†’ Restored â†’ Ground Truth comparison*

### Real-World Example

<div align="center">

| Input (Degraded) | Restored | Ground Truth |
|:----------------:|:--------:|:------------:|
| ![Input](docs/examples/input_example.png) | ![Restored](docs/examples/restored_example.png) | ![GT](docs/examples/gt_example.png) |
| Noisy + Blurred | **+8.95 dB PSNR** | Reference |
| PSNR: 15.45 dB | PSNR: 24.39 dB | - |
| SSIM: 0.2269 | SSIM: 0.8163 | - |

</div>

### Custom Degradation Pipeline

![Custom Degradation](docs/screenshots/degradation_interface.png)
*Interactive degradation tools: Create custom test scenarios with noise, blur, and custom kernels*

![Custom Kernel Editor](docs/screenshots/kernel_editor.png)
*7Ã—7 custom kernel editor with real-time visualization and blur strength control*

---

## âœ¨ Key Features

### ğŸ¤– Intelligent Degradation Detection

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Automatic Analysis                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  âœ“ Noise Type Detection              â”‚
â”‚  âœ“ Blur Severity Assessment          â”‚
â”‚  âœ“ Salt & Pepper Identification      â”‚
â”‚  âœ“ Overall Quality Estimation        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

- **Adaptive Processing**: Automatically adjusts parameters based on image analysis
- **Multi-Type Detection**: Identifies Gaussian noise, motion blur, and salt & pepper artifacts
- **Severity Classification**: Categorizes degradation levels (Low/Medium/High)

### ğŸ”¬ Advanced Restoration Algorithms

![Motion Deblurring Pipeline](docs/diagrams/deblurring_pipeline.png)
*Motion deblurring pipeline: Denoising â†’ PSF Estimation â†’ Deconvolution â†’ Enhancement*

**Core Techniques:**

1. **Richardson-Lucy Deconvolution** with Total Variation (TV) regularization
   - Iterative blind deconvolution
   - Adaptive iteration count (30-200 based on blur severity)
   - TV regularization every 6 iterations to prevent noise amplification

2. **Wiener Filtering** with adaptive balance parameter
   - Single-pass frequency domain filtering
   - SNR-based adaptive regularization
   - Luminance-channel processing for efficiency

3. **BM3D Denoising** (Block-Matching 3D)
   - State-of-the-art noise reduction
   - 3D collaborative filtering
   - Fallback to Wavelet + TV if unavailable

4. **PSF Estimation**
   - Radon transform for angle detection
   - Cepstrum analysis for length estimation
   - Robust against estimation failures

### ğŸ¨ Custom Degradation Tools

Create realistic test scenarios with full control:

- **Noise Addition**
  - Gaussian noise (Ïƒ: 1-30)
  - Salt & Pepper noise (amount: 0.01-0.1)
  
- **Blur Effects**
  - Motion blur (length: 3-15 px, angle: -90Â° to 90Â°)
  - Gaussian blur (Ïƒ: 0.5-2.5)
  - Average blur (box filter)
  - **Custom 7Ã—7 Kernel Editor** with interactive grid and blur strength control

- **Pipeline Management**
  - Step-by-step degradation history
  - Undo last operation
  - Reset to clean image
  - Export degraded images

### ğŸ“Š Comprehensive Quality Metrics

![Quality Metrics](docs/screenshots/quality_metrics.png)
*Real-time quality metrics with improvement indicators*

**Measured Metrics:**
- **PSNR** (Peak Signal-to-Noise Ratio) in dB
- **SSIM** (Structural Similarity Index)
- **MSE** (Mean Squared Error)
- **Sharpness** (Gradient magnitude-based)

All metrics show: Input â†’ Restored â†’ Improvement

---

## ğŸš€ Installation

### Prerequisites

- Python 3.8 or higher
- pip package manager
- Git

### Option 1: Standard Installation

```bash
# Clone the repository
git clone https://github.com/yourusername/visionrestore-pro.git
cd visionrestore-pro

# Create virtual environment
python -m venv venv
source venv/bin/activate  # Windows: venv\Scripts\activate

# Install dependencies
pip install -r requirements.txt

# Run the application
streamlit run app.py
```

### Option 2: With BM3D Support (Recommended)

```bash
# Install standard requirements
pip install -r requirements.txt

# Install BM3D for superior denoising
pip install bm3d

# Verify installation
python -c "import bm3d; print('BM3D installed successfully!')"
```

### Requirements

```txt
streamlit>=1.28.0
numpy>=1.24.0
opencv-python>=4.8.0
matplotlib>=3.7.0
seaborn>=0.12.0
Pillow>=10.0.0
scipy>=1.11.0
scikit-image>=0.21.0
pandas>=2.0.0
bm3d>=4.0.0  # Optional but recommended
PyWavelets>=1.4.0
```

---

## ğŸ¯ Quick Start

### 1. Launch Application

```bash
streamlit run app.py
```

The application opens at `http://localhost:8501`

### 2. Upload or Generate Image

**Option A: Upload Your Image**
- Click "Browse files" in the Image Input tab
- Select PNG, JPG, JPEG, BMP, or TIF file

**Option B: Generate Test Sample**
- Click "ğŸ² Generate Sample" for a synthetic test image
- Includes automatic ground truth for metrics

### 3. (Optional) Add Custom Degradations

Navigate to "ğŸ¨ Degrade Image" tab:

```
Clean Image
    â†“
[Add Gaussian Noise] â†’ Ïƒ = 15
    â†“
[Add Motion Blur] â†’ length=10, angle=30Â°
    â†“
[Set as Input] â†’ Ready for restoration
```

### 4. Run Restoration

- Go to "ğŸ”„ Restoration" tab
- Adjust parameters in sidebar (or enable Auto-Adapt)
- Click "ğŸš€ Start Restoration"
- View results with quality metrics

### 5. Analyze Results

Switch to "ğŸ“Š Analysis" tab for:
- Detailed quality metrics
- PSF analysis plots
- Pipeline stage visualization
- Algorithm insights

---

## ğŸ“– Usage Guide

### Basic Workflow Example

```python
# Command-line usage (without UI)
from visionrestore import restore_image_with_degradation_awareness
import numpy as np
from PIL import Image

# Load image
img = Image.open("blurry_image.jpg")
img_array = np.array(img).astype(np.float32) / 255.0

# Configure parameters
params = {
    'NOISE_SIGMA': 12.0,
    'WIENER_BAL': 0.01,
    'RL_ITERS': 100,
    'TV_WEIGHT': 0.008,
    'UNSHARP_AMOUNT': 0.6,
    'USE_BM3D': True,
    'AUTO_ADAPT': True
}

# Restore image
results = restore_image_with_degradation_awareness(img_array, params)

# Access results
restored = results['final']
degradation_info = results['degradation_info']
psf = results['psf']

# Save
Image.fromarray((restored * 255).astype('uint8')).save("restored.png")
```

### Parameter Guidelines

| Parameter | Range | Default | Description | Best For |
|-----------|-------|---------|-------------|----------|
| `NOISE_SIGMA` | 5.0-25.0 | 12.0 | Noise std deviation | Adjust based on visible noise |
| `WIENER_BAL` | 0.001-0.1 | 0.01 | Wiener regularization | Lower for sharp images |
| `RL_ITERS` | 30-200 | 100 | Richardson-Lucy iterations | Higher for severe blur |
| `TV_WEIGHT` | 0.001-0.05 | 0.008 | TV smoothing strength | Lower for texture-rich images |
| `UNSHARP_AMOUNT` | 0.1-1.0 | 0.6 | Sharpening strength | Adjust for desired sharpness |
| `USE_BM3D` | bool | True | Use BM3D denoising | Enable for best quality |
| `AUTO_ADAPT` | bool | True | Auto parameter tuning | Enable for automatic optimization |

---

## ğŸ—ï¸ Architecture

### High-Level System Flow

```mermaid
graph TB
    A[User Input] --> B{Input Source?}
    B -->|Upload| C[Load Image File]
    B -->|Generate| D[Synthetic Sample]
    B -->|Degrade| E[Custom Degradation]
    
    C --> F[Image Buffer]
    D --> F
    E --> F
    
    F --> G[Degradation Analysis]
    G --> H{Auto-Adapt?}
    H -->|Yes| I[Calculate Optimal Parameters]
    H -->|No| J[Use Manual Parameters]
    
    I --> K[Restoration Pipeline]
    J --> K
    
    K --> L[Quality Assessment]
    L --> M[Display Results]
    M --> N[Export Options]
    
    style A fill:#e3f2fd
    style F fill:#fff9c4
    style K fill:#c8e6c9
    style M fill:#f3e5f5
```

### Detailed User Workflow

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    VISIONRESTORE PRO WORKFLOW                    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

USER INTERACTION                    PROCESSING ENGINE
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€                  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Upload Image â”‚ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–º â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                   â”‚ Load & Validate  â”‚
       â”‚                           â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚                                    â”‚
       â–¼                                    â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Degrade    â”‚ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–º â”‚ Apply Noise/Blur â”‚
â”‚  (Optional)  â”‚                   â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                           â”‚
       â”‚                                    â”‚
       â”‚                                    â–¼
       â”‚                           â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
       â”‚                           â”‚  Analyze Image   â”‚
       â”‚                           â”‚  â€¢ Noise level   â”‚
       â”‚                           â”‚  â€¢ Blur severity â”‚
       â”‚                           â”‚  â€¢ Degradations  â”‚
       â”‚                           â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚                                    â”‚
       â–¼                                    â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Adjust     â”‚ â—„â”€â”€â”€ Auto-Adapt â”€â”€â”‚ Parameter Engine â”‚
â”‚  Parameters  â”‚                   â”‚  â€¢ Wiener K      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                   â”‚  â€¢ RL iterations â”‚
       â”‚                           â”‚  â€¢ TV weight     â”‚
       â”‚                           â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚                                    â”‚
       â–¼                                    â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚    Start     â”‚ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–º â”‚  STAGE 1: Denoiseâ”‚
â”‚ Restoration  â”‚                   â”‚  (Conditional)   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                   â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚                                    â”‚
       â”‚                                    â–¼
       â”‚                           â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
       â”‚                           â”‚ STAGE 2: PSF Est â”‚
       â”‚                           â”‚  â€¢ Radon (angle) â”‚
       â”‚                           â”‚  â€¢ Cepstrum (len)â”‚
       â”‚                           â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚                                    â”‚
       â”‚                                    â–¼
       â”‚                           â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
       â”‚                           â”‚ STAGE 3: Deblur  â”‚
       â”‚                           â”‚  â€¢ Wiener (base) â”‚
       â”‚                           â”‚  â€¢ RL (adaptive) â”‚
       â”‚                           â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚                                    â”‚
       â”‚                                    â–¼
       â”‚                           â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
       â”‚                           â”‚ STAGE 4: Enhance â”‚
       â”‚                           â”‚  â€¢ Unsharp mask  â”‚
       â”‚                           â”‚  â€¢ Post-process  â”‚
       â”‚                           â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚                                    â”‚
       â–¼                                    â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ View Results â”‚ â—„â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”‚ Quality Metrics  â”‚
â”‚  â€¢ Compare   â”‚                   â”‚  â€¢ PSNR          â”‚
â”‚  â€¢ Analyze   â”‚                   â”‚  â€¢ SSIM          â”‚
â”‚  â€¢ Download  â”‚                   â”‚  â€¢ MSE           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Processing Pipeline Overview

![Enhancement Pipeline](docs/diagrams/enhancement_pipeline.png)
*Complete image enhancement pipeline with automatic contrast, color correction, and detail enhancement*

### Motion Deblurring Pipeline

![Deblurring Pipeline](docs/diagrams/motion_deblurring_pipeline.png)

**Pipeline Stages:**

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  STAGE 1: DEGRADATION ANALYSIS                       â”‚
â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€                       â”‚
â”‚  â€¢ Detect noise type (Gaussian/Salt&Pepper)          â”‚
â”‚  â€¢ Measure blur severity (0.0 - 1.0)                 â”‚
â”‚  â€¢ Identify salt & pepper ratio                      â”‚
â”‚  â€¢ Calculate overall degradation score               â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                      â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  STAGE 2: CONDITIONAL DENOISING                      â”‚
â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€                      â”‚
â”‚  IF noise_level > 0.1 OR salt_pepper_present:        â”‚
â”‚    â†’ Convert RGB â†’ YCbCr                             â”‚
â”‚    â†’ Process Y channel:                              â”‚
â”‚      â€¢ Salt & Pepper â†’ Median filter                 â”‚
â”‚      â€¢ Gaussian â†’ BM3D or Wavelet + TV               â”‚
â”‚    â†’ Convert back to RGB                             â”‚
â”‚  ELSE: Skip denoising                                â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                      â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  STAGE 3: PSF ESTIMATION                             â”‚
â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€                                 â”‚
â”‚  â€¢ Radon transform â†’ Estimate angle (0-180Â°)         â”‚
â”‚  â€¢ Cepstrum analysis â†’ Estimate length (1-80 px)     â”‚
â”‚  â€¢ Generate motion blur kernel                       â”‚
â”‚  â€¢ Fallback: Default PSF if estimation fails         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                      â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  STAGE 4: ADAPTIVE DEBLURRING                        â”‚
â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€                        â”‚
â”‚  â€¢ ALWAYS: Wiener deconvolution (adaptive balance)   â”‚
â”‚  â€¢ IF blur_severity < 0.1: Wiener only (very mild)   â”‚
â”‚  â€¢ IF blur_severity < 0.7: Wiener only (mild/mod)    â”‚
â”‚  â€¢ IF blur_severity â‰¥ 0.7: Wiener + RL blend         â”‚
â”‚    - RL iterations: 30-200 (adaptive)                â”‚
â”‚    - Blend factor: based on severity                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                      â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  STAGE 5: ENHANCEMENT                                â”‚
â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€                                â”‚
â”‚  â€¢ Unsharp masking (adaptive strength)               â”‚
â”‚  â€¢ IF salt_pepper: Additional bilateral filter       â”‚
â”‚  â€¢ Clip to valid range [0, 1]                        â”‚
â”‚  â€¢ Output: Restored RGB image                        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Restoration Results Pipeline

![Pipeline Stages](docs/screenshots/pipeline_stages.png)
*Visual representation: Input â†’ Denoised â†’ Wiener Deconv â†’ Final Result*

### System Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    STREAMLIT WEB INTERFACE                 â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”â”‚
â”‚  â”‚  Upload  â”‚  â”‚  Degrade  â”‚  â”‚  Restore  â”‚  â”‚ Analysisâ”‚â”‚
â”‚  â”‚  & Input â”‚  â”‚  Pipeline â”‚  â”‚  Engine   â”‚  â”‚Dashboardâ”‚â”‚
â”‚  â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”˜â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”˜
        â”‚              â”‚              â”‚              â”‚
        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                            â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              IMAGE PROCESSING PIPELINE                     â”‚
â”‚                                                            â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚  Degradation Analysis Engine                       â”‚  â”‚
â”‚  â”‚  â€¢ analyze_noise_pattern()                         â”‚  â”‚
â”‚  â”‚  â€¢ analyze_blur_severity()                         â”‚  â”‚
â”‚  â”‚  â€¢ detect_salt_pepper_noise()                      â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚                            â–¼                               â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚  Adaptive Denoising Module                         â”‚  â”‚
â”‚  â”‚  â€¢ denoise_luminance() - BM3D/Wavelet              â”‚  â”‚
â”‚  â”‚  â€¢ YCbCr color space conversion                    â”‚  â”‚
â”‚  â”‚  â€¢ TV regularization                               â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚                            â–¼                               â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚  PSF Estimation Module                             â”‚  â”‚
â”‚  â”‚  â€¢ estimate_motion_psf_robust()                    â”‚  â”‚
â”‚  â”‚  â€¢ Radon transform (angle detection)               â”‚  â”‚
â”‚  â”‚  â€¢ Cepstrum analysis (length estimation)           â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚                            â–¼                               â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚  Adaptive Deblurring Module                        â”‚  â”‚
â”‚  â”‚  â€¢ wiener_deconvolution_rgb() - Always applied     â”‚  â”‚
â”‚  â”‚  â€¢ rl_tv_deconvolution() - Severe blur only        â”‚  â”‚
â”‚  â”‚  â€¢ Adaptive algorithm selection                    â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚                            â–¼                               â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚  Enhancement Module                                â”‚  â”‚
â”‚  â”‚  â€¢ Unsharp masking (adaptive)                      â”‚  â”‚
â”‚  â”‚  â€¢ Bilateral filtering (conditional)               â”‚  â”‚
â”‚  â”‚  â€¢ Multi-scale sharpening                          â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                             â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              QUALITY ASSESSMENT MODULE                     â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚   PSNR   â”‚  â”‚   SSIM   â”‚  â”‚   MSE    â”‚  â”‚Sharpness â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ§® Core Algorithms

### 1. Richardson-Lucy Deconvolution

**Iterative blind deconvolution with Total Variation regularization**

#### Algorithm Overview Diagram

```mermaid
graph TD
    A[Start: Blurry Image y] --> B[Initialize: xâ° = y]
    B --> C{Iteration k < max_iters?}
    C -->|No| D[Return Result]
    C -->|Yes| E[Forward Blur: Å· = H âŠ— x^k]
    E --> F[Compute Error: e = y / Å·]
    F --> G[Back-project: correction = H^T âŠ— e]
    G --> H[Update: x^k+1 = x^k Â· correction]
    H --> I[Clip: x^k+1 = clip_x^k+1, 0, 1_]
    I --> J{k % 6 == 0?}
    J -->|Yes| K[Apply TV Denoising]
    J -->|No| L[k = k + 1]
    K --> L
    L --> C
    
    style A fill:#e3f2fd
    style D fill:#c8e6c9
    style K fill:#fff9c4
```

#### Detailed Processing Flow

```
Richardson-Lucy with TV Regularization
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

INITIALIZATION:
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ xâ½â°â¾ = y (observed blurry image)   â”‚
â”‚ H = PSF kernel                      â”‚
â”‚ H_flip = flip(H) horizontally/vert  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                  â”‚
         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”
         â”‚ FOR k = 0 to N  â”‚
         â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                  â”‚
STEP 1: FORWARD MODEL
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Simulate blur on current estimate:  â”‚
â”‚                                      â”‚
â”‚    Å· = H âŠ— xâ½áµâ¾                     â”‚
â”‚    Å· = clip(Å·, Îµ, 1)                â”‚
â”‚                                      â”‚
â”‚ (What would x^k look like if        â”‚
â”‚  it were blurred by PSF?)           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                  â”‚
STEP 2: ERROR COMPUTATION
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Calculate pixel-wise error ratio:   â”‚
â”‚                                      â”‚
â”‚    error_ratio = y / Å·               â”‚
â”‚                                      â”‚
â”‚ Where:                               â”‚
â”‚  â€¢ ratio > 1: Need more intensity    â”‚
â”‚  â€¢ ratio < 1: Need less intensity    â”‚
â”‚  â€¢ ratio â‰ˆ 1: Estimate is good       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                  â”‚
STEP 3: BACK-PROJECTION
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Distribute error back to image:     â”‚
â”‚                                      â”‚
â”‚    correction = H_flip âŠ— error_ratioâ”‚
â”‚                                      â”‚
â”‚ (Use transpose of PSF to            â”‚
â”‚  backpropagate the correction)      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                  â”‚
STEP 4: MULTIPLICATIVE UPDATE
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Update estimate:                     â”‚
â”‚                                      â”‚
â”‚    xâ½áµâºÂ¹â¾ = xâ½áµâ¾ Â· correction        â”‚
â”‚    xâ½áµâºÂ¹â¾ = clip(xâ½áµâºÂ¹â¾, 0, 1)       â”‚
â”‚                                      â”‚
â”‚ (Multiplicative ensures positivity) â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                  â”‚
         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”
         â”‚  k % 6 == 0?    â”‚
         â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”˜
            NOâ”‚     YESâ”‚
              â”‚        â”‚
              â”‚        â–¼
              â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
              â”‚  â”‚ STEP 5: TV Denoiseâ”‚
              â”‚  â”‚                   â”‚
              â”‚  â”‚ xâ½áµâºÂ¹â¾ â† TV(xâ½áµâºÂ¹â¾)â”‚
              â”‚  â”‚                   â”‚
              â”‚  â”‚ (Reduce noise     â”‚
              â”‚  â”‚  amplification)   â”‚
              â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
              â”‚           â”‚
              â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                     â”‚
         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
         â”‚ k = k + 1              â”‚
         â”‚ Continue to next iter  â”‚
         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                     â”‚
         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
         â”‚ CONVERGENCE CHECK      â”‚
         â”‚ k >= max_iters?        â”‚
         â””â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
               YESâ”‚
                  â–¼
         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
         â”‚ Return xâ½áµâºÂ¹â¾    â”‚
         â”‚ (Deblurred img) â”‚
         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

KEY PROPERTIES:
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
 âœ“ Bayesian framework (ML estimation)
 âœ“ Multiplicative update â†’ positivity
 âœ“ Total intensity preserved
 âœ“ TV regularization â†’ noise control
 âœ“ Typical iterations: 60-200
```

#### Mathematical Foundation

```
Update Rule: x^(k+1) = x^(k) Â· [H^T âŠ— (y / (H âŠ— x^(k)))]

Where:
  x^(k) = Current estimate
  H = Point Spread Function (PSF)
  H^T = Transposed/flipped PSF
  y = Observed blurry image
  âŠ— = Convolution operator
```

#### Why It Works

```
INTUITION:
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
1. Start with blurry image as initial guess
2. Simulate: "If this were the sharp image, 
             what would it look like blurred?"
3. Compare simulated blur with actual blur
4. Use difference to improve estimate
5. Repeat until convergence

BAYESIAN VIEW:
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
Maximizes: P(x|y) = P(y|x) Â· P(x) / P(y)

Where:
  P(x|y) = Probability of sharp image given blurry
  P(y|x) = Poisson likelihood (blur model)
  P(x)   = Prior (enforced by TV regularization)
```

**Key Properties:**
- âœ… Maintains positivity (multiplicative update)
- âœ… Preserves total intensity
- âœ… Converges to maximum likelihood estimate
- âœ… TV regularization prevents noise amplification

**Time Complexity:** O(NÂ² log N Ã— I) where I = iterations

---

### 2. Wiener Filtering

**Optimal linear filtering in frequency domain**

#### Algorithm Flow Diagram

```mermaid
graph TB
    A[RGB Image] --> B[Convert to YCbCr]
    B --> C[Extract Y Channel]
    C --> D[Estimate SNR]
    D --> E[Calculate Adaptive K]
    E --> F{K = K_base / _1 + Î±Â·SNR_}
    F --> G[FFT_Y_]
    F --> H[FFT_PSF_]
    G --> I[Apply Wiener Filter]
    H --> I
    I --> J[IFFT â†’ Deblurred Y]
    J --> K[Clip to _0,1_]
    K --> L[Replace Y in YCbCr]
    L --> M[Convert to RGB]
    M --> N[Deblurred RGB Image]
    
    style A fill:#e3f2fd
    style E fill:#fff9c4
    style N fill:#c8e6c9
```

#### Detailed Processing Pipeline

```
Adaptive Wiener Deconvolution Pipeline
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

INPUT: RGB Image + PSF Kernel
OUTPUT: Deblurred RGB Image

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ STEP 1: COLOR SPACE CONVERSION              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                             â”‚
â”‚  RGB â†’ YCbCr Color Space                    â”‚
â”‚                                             â”‚
â”‚       â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”                           â”‚
â”‚       â”‚   RGB   â”‚                           â”‚
â”‚       â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”˜                           â”‚
â”‚            â”‚                                â”‚
â”‚      cv2.cvtColor()                         â”‚
â”‚            â”‚                                â”‚
â”‚       â”Œâ”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”                          â”‚
â”‚       â”‚  YCbCr   â”‚                          â”‚
â”‚       â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤                          â”‚
â”‚       â”‚ Y:  Luma â”‚ â† Process this channel   â”‚
â”‚       â”‚ Cb: Blue â”‚ â† Keep unchanged         â”‚
â”‚       â”‚ Cr: Red  â”‚ â† Keep unchanged         â”‚
â”‚       â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                          â”‚
â”‚                                             â”‚
â”‚  WHY? Most blur/noise in luminance          â”‚
â”‚       3Ã— faster than RGB processing         â”‚
â”‚       Preserves color information           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
              â”‚
              â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ STEP 2: SNR ESTIMATION & ADAPTIVE BALANCE   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                             â”‚
â”‚  Estimate Signal-to-Noise Ratio:           â”‚
â”‚                                             â”‚
â”‚     median = median(Y)                      â”‚
â”‚     MAD = median(|Y - median|)              â”‚
â”‚     Ïƒ_noise = 1.4826 Ã— MAD                  â”‚
â”‚     Ïƒ_signal = std(Y)                       â”‚
â”‚     SNR = ÏƒÂ²_signal / ÏƒÂ²_noise              â”‚
â”‚                                             â”‚
â”‚  Calculate Adaptive Balance:                â”‚
â”‚                                             â”‚
â”‚     K_adaptive = K_base / (1 + 0.1 Ã— SNR)   â”‚
â”‚                                             â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”          â”‚
â”‚  â”‚ High SNR â†’ Low K              â”‚          â”‚
â”‚  â”‚   (clean image, aggressive)   â”‚          â”‚
â”‚  â”‚                               â”‚          â”‚
â”‚  â”‚ Low SNR â†’ High K              â”‚          â”‚
â”‚  â”‚   (noisy image, conservative) â”‚          â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
              â”‚
              â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ STEP 3: FREQUENCY DOMAIN FILTERING          â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                             â”‚
â”‚  A. Forward FFT:                            â”‚
â”‚     â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€                           â”‚
â”‚     Y(Ï‰) = FFT(Y_spatial)                   â”‚
â”‚     H(Ï‰) = FFT(PSF)                         â”‚
â”‚                                             â”‚
â”‚  B. Compute Wiener Filter:                  â”‚
â”‚     â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€                  â”‚
â”‚                H*(Ï‰)                         â”‚
â”‚     W(Ï‰) = â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€                â”‚
â”‚            |H(Ï‰)|Â² + K_adaptive             â”‚
â”‚                                             â”‚
â”‚     Where H*(Ï‰) = complex conjugate         â”‚
â”‚                                             â”‚
â”‚  C. Apply Filter:                           â”‚
â”‚     â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€                           â”‚
â”‚     XÌ‚(Ï‰) = W(Ï‰) Â· Y(Ï‰)                      â”‚
â”‚                                             â”‚
â”‚  D. Inverse FFT:                            â”‚
â”‚     â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€                           â”‚
â”‚     deblurred_Y = IFFT(XÌ‚(Ï‰))               â”‚
â”‚     deblurred_Y = clip(deblurred_Y, 0, 1)   â”‚
â”‚                                             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
              â”‚
              â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ STEP 4: COLOR RECONSTRUCTION                â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                             â”‚
â”‚  Replace Y channel in YCbCr:                â”‚
â”‚                                             â”‚
â”‚     YCbCr_new[..., 0] = deblurred_Y         â”‚
â”‚     YCbCr_new[..., 1] = Cb (unchanged)      â”‚
â”‚     YCbCr_new[..., 2] = Cr (unchanged)      â”‚
â”‚                                             â”‚
â”‚  Convert back to RGB:                       â”‚
â”‚                                             â”‚
â”‚     RGB_deblurred = cv2.cvtColor(           â”‚
â”‚                         YCbCr_new,          â”‚
â”‚                         COLOR_YCbCr2RGB)    â”‚
â”‚                                             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
              â”‚
              â–¼
         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
         â”‚ Deblurred Image â”‚
         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

FREQUENCY DOMAIN VISUALIZATION:
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

Spatial Domain          Frequency Domain
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€           â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

  Blurry Image              Y(Ï‰)
       â”‚                     â”‚
       â”‚ FFT              â”Œâ”€â”€â”´â”€â”€â”
       â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–ºâ”‚     â”‚
                          â”‚     â”‚
  PSF Kernel               H(Ï‰)â”‚
       â”‚                  â”‚     â”‚
       â”‚ FFT           â”Œâ”€â”€â”´â”€â”€â”€â”€â”€â–¼â”€â”€â”
       â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–ºâ”‚  Wiener   â”‚
                       â”‚  W(Ï‰)     â”‚
                       â”‚ H*/|H|Â²+K â”‚
                       â””â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜
                             â”‚
                        XÌ‚(Ï‰) = WÂ·Y
                             â”‚
                        IFFT â”‚
                             â–¼
                      Deblurred Image
```

#### SNR-Based Adaptation Visualization

```
K (Regularization) vs SNR
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

  High K                             Low K
(Conservative)                  (Aggressive)
     â”‚                               â”‚
     â”‚                               â”‚
  0.1â”œâ”€â”                             â”‚
     â”‚ â”‚                             â”‚
     â”‚ â”‚â•²                            â”‚
     â”‚ â”‚ â•²                           â”‚
  0.05â”‚ â”‚  â•²___                      â”‚
     â”‚ â”‚      â”€â”€â”€___                 â”‚
     â”‚ â”‚            â”€â”€â”€___           â”‚
  0.01â”œâ”€â”˜                  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
     â”‚                               â”‚
     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
     0     5    10    15    20       SNR

Noisy Image         Mixed         Clean Image
(K = 0.1)        (K = 0.01)      (K = 0.001)
```

**Frequency Domain Formula:**

```
H_wiener(Ï‰) = H*(Ï‰) / (|H(Ï‰)|Â² + K)
XÌ‚(Ï‰) = H_wiener(Ï‰) Â· Y(Ï‰)

Adaptive Balance:
K = K_base / (1 + Î± Â· SNR)
  
  High SNR â†’ Small K â†’ Aggressive deconvolution
  Low SNR  â†’ Large K â†’ Conservative (prevents noise)
```

**Processing Flow:**

```
1. Convert RGB â†’ YCbCr (process luminance only)
2. Extract Y channel
3. Estimate SNR â†’ Compute adaptive K
4. Apply Wiener filter in frequency domain:
   â€¢ FFT(Y) â†’ Apply H_wiener â†’ IFFT
5. Convert back to RGB
```

**Advantages:**
- âœ… Single-pass computation (very fast)
- âœ… Closed-form solution
- âœ… Optimal for Gaussian noise
- âœ… Adaptive regularization prevents artifacts

**Time Complexity:** O(NÂ² log N) - single FFT pass

---

### 3. PSF Estimation

**Two-stage robust estimation: Radon Transform + Cepstrum Analysis**

#### Complete PSF Estimation Pipeline

```mermaid
graph TB
    A[Blurry Image] --> B[Convert to Grayscale]
    B --> C[Apply Circular Mask]
    C --> D[STAGE 1: Radon Transform]
    D --> E[Compute at 90 angles]
    E --> F[Calculate variance per angle]
    F --> G[Î¸_blur = argmax_variance_]
    
    G --> H[STAGE 2: Rotate by -Î¸]
    H --> I[Compute FFT]
    I --> J[Log Magnitude Spectrum]
    J --> K[Inverse FFT: Cepstrum]
    K --> L[Extract Center Profile]
    L --> M[Find Peaks]
    M --> N[Measure Peak Distance]
    N --> O[Length = distance]
    
    O --> P[Generate PSF]
    G --> P
    P --> Q[motion_blur_psf_length, angle_]
    
    style A fill:#e3f2fd
    style D fill:#fff9c4
    style K fill:#ffe0b2
    style Q fill:#c8e6c9
```

#### Stage 1: Angle Detection via Radon Transform

```
RADON TRANSFORM FOR ANGLE DETECTION
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

CONCEPT:
â”€â”€â”€â”€â”€â”€â”€â”€
Motion blur creates parallel streaks
Radon transform projects image at different angles
Maximum variance occurs perpendicular to blur direction


VISUAL REPRESENTATION:
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

Blurry Image (with horizontal blur):
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•  â”‚
â”‚ â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•  â”‚  Blur direction: â†’
â”‚ â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•  â”‚  (0Â°)
â”‚ â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜


Radon Transform at Different Angles:
                                                  Variance
  Î¸ = 0Â° (parallel to blur)      Low  â–’â–’â–’â–‘â–‘â–‘â–‘
  Î¸ = 45Â°                        Mid  â–’â–’â–’â–’â–’â–’â–‘â–‘
  Î¸ = 90Â° (perpendicular)        High â–’â–’â–’â–’â–’â–’â–’â–’â–’  â† MAX!
  Î¸ = 135Â°                       Mid  â–’â–’â–’â–’â–’â–’â–‘â–‘
  Î¸ = 180Â°                       Low  â–’â–’â–’â–‘â–‘â–‘â–‘


ALGORITHM FLOW:
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

Input: Grayscale blurry image
                â”‚
                â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 1. Apply Circular Mask        â”‚
â”‚    (eliminate edge artifacts) â”‚
â”‚                               â”‚
â”‚    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”            â”‚
â”‚    â”‚   â—â—â—â—â—â—â—   â”‚            â”‚
â”‚    â”‚  â—â—â—â—â—â—â—â—â—  â”‚            â”‚
â”‚    â”‚ â—â—â—â—â—â—â—â—â—â—â— â”‚            â”‚
â”‚    â”‚  â—â—â—â—â—â—â—â—â—  â”‚            â”‚
â”‚    â”‚   â—â—â—â—â—â—â—   â”‚            â”‚
â”‚    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                â”‚
                â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 2. Compute Radon Transform    â”‚
â”‚    at 90 angles (0Â° to 180Â°)  â”‚
â”‚                               â”‚
â”‚    FOR Î¸ = 0Â° to 180Â° (step 2Â°)â”‚
â”‚      R(Ï,Î¸) = âˆ« img along lineâ”‚
â”‚                               â”‚
â”‚    Creates sinogram:          â”‚
â”‚         Î¸ â†’                   â”‚
â”‚    Ï â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”             â”‚
â”‚    â†“ â”‚â–’â–’â–‘â–‘â–’â–’â–‘â–‘â”‚             â”‚
â”‚      â”‚â–‘â–’â–’â–’â–’â–‘â–‘â”‚             â”‚
â”‚      â”‚â–‘â–‘â–’â–’â–’â–’â–’â–‘â”‚             â”‚
â”‚      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                â”‚
                â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 3. Variance Analysis          â”‚
â”‚                               â”‚
â”‚    FOR each angle Î¸:          â”‚
â”‚      var(Î¸) = Var(R(:,Î¸))     â”‚
â”‚                               â”‚
â”‚    Plot:                      â”‚
â”‚    Variance                   â”‚
â”‚      â–²                        â”‚
â”‚      â”‚        â•­â•®              â”‚
â”‚      â”‚       â•±  â•²             â”‚
â”‚      â”‚      â•±    â•²            â”‚
â”‚      â”‚     â•±      â•²           â”‚
â”‚      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–º Î¸     â”‚
â”‚         0Â°  90Â° 180Â°          â”‚
â”‚             â†‘                 â”‚
â”‚          Maximum              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                â”‚
                â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 4. Select Maximum             â”‚
â”‚                               â”‚
â”‚    Î¸_blur = argmax(variance)  â”‚
â”‚                               â”‚
â”‚    This angle is PERPENDICULARâ”‚
â”‚    to actual blur direction   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜


MATHEMATICAL FORMULATION:
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

Radon Transform at angle Î¸:
  R(Ï,Î¸) = âˆ«âˆ« f(x,y) Î´(xÂ·cosÎ¸ + yÂ·sinÎ¸ - Ï) dx dy

Where:
  f(x,y) = image intensity
  Î´ = Dirac delta function
  Ï = distance from origin
  Î¸ = angle of projection

Variance Calculation:
  var(Î¸) = Variance(R(:,Î¸))
  Î¸_blur = Î¸ where var(Î¸) is maximum
```

#### Stage 2: Length Detection via Cepstrum Analysis

```
CEPSTRUM ANALYSIS FOR LENGTH DETECTION
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

CONCEPT:
â”€â”€â”€â”€â”€â”€â”€â”€
Cepstrum = "spectrum of spectrum"
Separates image content from blur pattern
Motion blur creates periodic pattern in cepstrum


ALGORITHM FLOW:
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

Input: Image + detected angle Î¸_blur
                â”‚
                â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 1. Align Blur Horizontally        â”‚
â”‚                                   â”‚
â”‚    rotated = rotate(img, -Î¸_blur) â”‚
â”‚                                   â”‚
â”‚    Before:        After:          â”‚
â”‚    â•±â•±â•±â•±â•±          â•â•â•â•â•           â”‚
â”‚   â•±â•±â•±â•±â•±           â•â•â•â•â•           â”‚
â”‚  â•±â•±â•±â•±â•±            â•â•â•â•â•           â”‚
â”‚                                   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                â”‚
                â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 2. Compute Magnitude Spectrum     â”‚
â”‚                                   â”‚
â”‚    F(Ï‰) = FFT(rotated_image)      â”‚
â”‚    M(Ï‰) = |F(Ï‰)| + Îµ              â”‚
â”‚                                   â”‚
â”‚    Spatial          Frequency     â”‚
â”‚    Domain           Domain        â”‚
â”‚    â”Œâ”€â”€â”€â”€â”            â”Œâ”€â”€â”€â”€â”       â”‚
â”‚    â”‚â–ˆâ–ˆâ–ˆâ–ˆâ”‚   FFT      â”‚â–“â–“â–‘â–‘â”‚       â”‚
â”‚    â”‚â–ˆâ–ˆâ–ˆâ–ˆâ”‚  â”€â”€â”€â”€â”€â–º    â”‚â–“â–‘â–‘â–“â”‚       â”‚
â”‚    â”‚â–ˆâ–ˆâ–ˆâ–ˆâ”‚            â”‚â–‘â–‘â–“â–“â”‚       â”‚
â”‚    â””â”€â”€â”€â”€â”˜            â””â”€â”€â”€â”€â”˜       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                â”‚
                â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 3. Log Transform                  â”‚
â”‚                                   â”‚
â”‚    L(Ï‰) = log(M(Ï‰))               â”‚
â”‚                                   â”‚
â”‚    WHY? Separates multiplicative  â”‚
â”‚         convolution into addition:â”‚
â”‚                                   â”‚
â”‚    Spatial: y = x * h             â”‚
â”‚    Freq:    Y = X Â· H             â”‚
â”‚    Log:     log(Y) = log(X)+log(H)â”‚
â”‚                                   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                â”‚
                â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 4. Inverse FFT â†’ Cepstrum         â”‚
â”‚                                   â”‚
â”‚    C = IFFT(L(Ï‰))                 â”‚
â”‚    C = IFFT(log(|FFT(img)|))      â”‚
â”‚                                   â”‚
â”‚    Cepstrum "Domain":             â”‚
â”‚    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”       â”‚
â”‚    â”‚     â–²    â–²    â–²      â”‚       â”‚
â”‚    â”‚    â•±â”‚â•²  â•±â”‚â•²  â•±â”‚â•²     â”‚       â”‚
â”‚    â”‚   â•± â”‚ â•²â•± â”‚ â•²â•± â”‚ â•²    â”‚       â”‚
â”‚    â”‚â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”‚       â”‚
â”‚    â”‚  ^   ^   ^   ^   ^   â”‚       â”‚
â”‚    â”‚  â”‚   â”‚   â”‚   â”‚   â”‚   â”‚       â”‚
â”‚    â”‚  Peaks from blur     â”‚       â”‚
â”‚    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                â”‚
                â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 5. Extract Center Row Profile     â”‚
â”‚                                   â”‚
â”‚    profile = C[height/2, :]       â”‚
â”‚                                   â”‚
â”‚    Amplitude                      â”‚
â”‚      â–²                            â”‚
â”‚      â”‚   â•±â•²       â•±â•²       â•±â•²     â”‚
â”‚      â”‚  â•±  â•²     â•±  â•²     â•±  â•²    â”‚
â”‚      â”‚ â•±    â•²   â•±    â•²   â•±    â•²   â”‚
â”‚      â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–º Positionâ”‚
â”‚      â”‚   d    d    d              â”‚
â”‚      â”‚   â””â”€â”€â”€â”€â”˜                   â”‚
â”‚      â”‚  Periodic spacing = length â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                â”‚
                â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 6. Peak Detection                 â”‚
â”‚                                   â”‚
â”‚    peaks = find_peaks(|profile|)  â”‚
â”‚                                   â”‚
â”‚    Criteria:                      â”‚
â”‚    â€¢ distance > 2 pixels          â”‚
â”‚    â€¢ height > 1.05 Ã— mean         â”‚
â”‚                                   â”‚
â”‚    Select peak closest to center: â”‚
â”‚    center = len(profile) / 2      â”‚
â”‚    best_peak = argmin(|peak-center|)â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                â”‚
                â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 7. Calculate Length               â”‚
â”‚                                   â”‚
â”‚    length = |best_peak - center|  â”‚
â”‚    length = clamp(length, 1, 80)  â”‚
â”‚                                   â”‚
â”‚    This is the motion blur length â”‚
â”‚    in pixels!                     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜


VISUAL EXAMPLE:
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

Original Blur:     Cepstrum Profile:
â•â•â•â•â•â•â•â•â•          
â•â•â•â•â•â•â•â•â•            Peak distance
â•â•â•â•â•â•â•â•â•               â†“
Motion: 15px        â”‚  â•±â•²    â•±â•²
                    â”‚ â•±  â•²  â•±  â•²
                    â”‚â•±    â•²â•±    â•²
                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
                    Center  15px

WHY IT WORKS:
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
â€¢ Motion blur = convolution with line
â€¢ Convolution in spatial = multiplication in frequency
â€¢ Log converts multiplication to addition
â€¢ IFFT of log separates blur signature
â€¢ Blur signature = periodic peaks
â€¢ Peak spacing = blur length
```

#### Final PSF Generation

```
PSF GENERATION
â•â•â•â•â•â•â•â•â•â•â•â•â•â•

Inputs: length, angle
Output: PSF kernel

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Generate Motion Blur Kernel     â”‚
â”‚                                 â”‚
â”‚ 1. Calculate kernel size:       â”‚
â”‚    size = ceil(length) | 1      â”‚
â”‚    (must be odd)                â”‚
â”‚                                 â”‚
â”‚ 2. Create line from center:     â”‚
â”‚    FOR x in linspace(-len/2, len/2)â”‚
â”‚      xi = center + xÂ·cos(Î¸)     â”‚
â”‚      yi = center + xÂ·sin(Î¸)     â”‚
â”‚      PSF[yi, xi] += 1.0         â”‚
â”‚                                 â”‚
â”‚ 3. Normalize:                   â”‚
â”‚    PSF = PSF / sum(PSF)         â”‚
â”‚                                 â”‚
â”‚ Examples:                       â”‚
â”‚                                 â”‚
â”‚ Î¸=0Â°, len=5:   Î¸=45Â°, len=7:   â”‚
â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”‚
â”‚ â”‚0 0 0 0 0â”‚    â”‚â–“ 0 0 0 0â”‚     â”‚
â”‚ â”‚0 0 0 0 0â”‚    â”‚0 â–“ 0 0 0â”‚     â”‚
â”‚ â”‚â–“â–“â–“â–“â–“â”‚    â”‚0 0 â–“ 0 0â”‚     â”‚
â”‚ â”‚0 0 0 0 0â”‚    â”‚0 0 0 â–“ 0â”‚     â”‚
â”‚ â”‚0 0 0 0 0â”‚    â”‚0 0 0 0 â–“â”‚     â”‚
â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Two-Stage Approach:**

#### Stage 1: Angle Detection

```
METHOD: Radon Transform
  1. Apply circular mask (reduce edge artifacts)
  2. Compute Radon transform at 90 angles (0Â° to 180Â°)
  3. Calculate variance for each angle
  4. Select angle with maximum variance
  
THEORY: Motion blur creates maximum variance 
        perpendicular to motion direction
```

#### Stage 2: Length Estimation

```
METHOD: Cepstrum Analysis
  1. Rotate image by -angle (align blur horizontally)
  2. Compute magnitude spectrum: M(Ï‰) = |FFT(image)|
  3. Log transform: L(Ï‰) = log(M(Ï‰))
  4. Inverse FFT: Cepstrum = IFFT(L(Ï‰))
  5. Find peaks in center row
  6. Peak distance from center = blur length
  
THEORY: Cepstrum separates image content from 
        blur signature
```

**Robustness Features:**
- âœ… Circular mask eliminates edge artifacts
- âœ… Multi-angle sampling (90 directions)
- âœ… Peak validation with thresholds
- âœ… Fallback to default PSF if estimation fails
- âœ… Length clamping to reasonable range [1, 80] pixels

**Time Complexity:** O(NÂ² log N + NÎ¸) where Î¸ = 90

---

### 4. BM3D Denoising

**State-of-the-art Block-Matching 3D collaborative filtering**

**Two-Stage Process:**

```
STAGE 1: Basic Estimate (Hard Thresholding)
  1. Block Matching: Find similar 8Ã—8 blocks
  2. 3D Grouping: Stack similar blocks â†’ 3D arrays
  3. 3D DCT Transform: Apply to grouped blocks
  4. Hard Thresholding: Zero out small coefficients
  5. Inverse Transform & Aggregation
  
STAGE 2: Final Estimate (Wiener Filtering)
  1. Use same block groups as Stage 1
  2. Transform both noisy and basic estimate
  3. Wiener filtering in 3D transform domain
  4. Inverse transform & aggregate
```

**Why Luminance Only?**
- Most noise appears in Y channel (luminance)
- Human eye more sensitive to luminance than color
- 3Ã— faster than RGB processing
- Preserves color information
- Prevents color artifacts

**Performance:**
- **PSNR Gain:** +3-5 dB over wavelet denoising
- **Processing Time:** ~2-5 seconds for 512Ã—512 image

---

### 5. Adaptive Processing Strategy

**Intelligent algorithm selection based on degradation analysis**

```
DECISION TREE:

Blur Severity < 0.1?
  â”œâ”€ YES â†’ Wiener only (very mild) - conservative balance
  â””â”€ NO â†’ Continue...

Blur Severity < 0.7?
  â”œâ”€ YES â†’ Wiener only (mild/moderate) - standard balance
  â””â”€ NO â†’ Continue...

Blur Severity â‰¥ 0.7?
  â””â”€ YES â†’ Wiener + Richardson-Lucy
           â€¢ RL iterations: 30-200 (adaptive)
           â€¢ Blend: Î±Â·RL + (1-Î±)Â·Wiener
           â€¢ Î± = min(1.0, (severity - 0.7) Ã— 3.0)
```

**Parameter Adaptation Table:**

| Blur Severity | Wiener Balance | RL Applied? | RL Iters | Blend Factor |
|---------------|----------------|-------------|----------|--------------|
| < 0.1 (Very Mild) | base Ã— 2.0 | âŒ No | - | - |
| 0.1 - 0.3 (Mild) | base Ã— 1.5 | âŒ No | - | - |
| 0.3 - 0.5 (Moderate) | base Ã— 1.0 | âŒ No | - | - |
| 0.5 - 0.7 (Strong) | base Ã— 0.7 | âŒ No | - | - |
| â‰¥ 0.7 (Severe) | base Ã— 0.5 | âœ… Yes | 60-200 | (severity-0.7)Ã—3 |

**Key Innovation:** Progressive enhancement prevents over-processing of mildly degraded images while aggressively treating severely degraded ones.

---

## âš¡ Performance

### Benchmark Results

**Test Configuration:**
- **Hardware:** Intel i7-10700K @ 3.8GHz, 32GB DDR4
- **Software:** Python 3.10.11, OpenCV 4.8.0
- **Image Size:** 512Ã—512 RGB
- **Test Set:** 18 samples with varying degradations

#### Processing Time Breakdown

| Operation | Time (seconds) | Percentage |
|-----------|----------------|------------|
| Denoising (BM3D) | 2.3 | 18.4% |
| PSF Estimation | 1.2 | 9.6% |
| Wiener Deblurring | 0.5 | 4.0% |
| RL Deblurring (100 iter) | 8.7 | 69.6% |
| Enhancement | 0.3 | 2.4% |
| **Full Pipeline** | **12.5** | **100%** |

#### Quality Improvement Statistics

![Performance Results](docs/charts/performance_summary.png)

**PSNR Results:**

| Metric | Value |
|--------|-------|
| Average Improvement | **+0.70 dB** |
| Best Improvement | **+2.19 dB** |
| Worst Improvement | -0.83 dB |
| Improved Samples | **14/18 (77.8%)** |

**SSIM Results:**

| Metric | Value |
|--------|-------|
| Average Improvement | **+0.2296** |
| Best Improvement | **+0.3993** |
| Worst Improvement | -0.0240 |
| Improved Samples | **17/18 (94.4%)** |

**Overall Success Rate:** 18/18 samples processed successfully (100%)

### PSNR Improvements by Sample

![PSNR Improvements](docs/charts/psnr_improvements.png)

| Sample | PSNR Improvement (dB) | Status |
|--------|----------------------|--------|
| Sample 01 | +0.99 | âœ… |
| Sample 02 | +0.41 | âœ… |
| Sample 03 | +0.71 | âœ… |
| Sample 04 | +1.81 | âœ… |
| Sample 05 | -0.01 | âš ï¸ |
| Sample 06 | -0.56 | âš ï¸ |
| Sample 07 | +1.23 | âœ… |
| Sample 08 | +0.96 | âœ… |
| Sample 09 | +0.41 | âœ… |
| Sample 10 | +1.11 | âœ… |
| Sample 11 | +2.19 | âœ… |
| Sample 12 | +0.28 | âœ… |
| Sample 13 | +1.36 | âœ… |
| Sample 14 | +1.48 | âœ… |
| Sample 15 | +0.99 | âœ… |
| Sample 16 | +0.46 | âœ… |
| Sample 17 | -0.35 | âš ï¸ |
| Sample 18 | -0.83 | âš ï¸ |

### SSIM Improvements by Sample

![SSIM Improvements](docs/charts/ssim_improvements.png)

| Sample | SSIM Improvement | Status |
|--------|------------------|--------|
| Sample 01 | +0.1803 | âœ… |
| Sample 02 | +0.2462 | âœ… |
| Sample 03 | +0.2352 | âœ… |
| Sample 04 | +0.3993 | âœ… |
| Sample 05 | +0.2716 | âœ… |
| Sample 06 | +0.2023 | âœ… |
| Sample 07 | +0.2097 | âœ… |
| Sample 08 | +0.1812 | âœ… |
| Sample 09 | +0.2232 | âœ… |
| Sample 10 | +0.2452 | âœ… |
| Sample 11 | +0.3211 | âœ… |
| Sample 12 | +0.3902 | âœ… |
| Sample 13 | +0.2431 | âœ… |
| Sample 14 | +0.2081 | âœ… |
| Sample 15 | +0.1913 | âœ… |
| Sample 16 | +0.1807 | âœ… |
| Sample 17 | +0.2270 | âœ… |
| Sample 18 | -0.0240 | âš ï¸ |

### Computational Complexity

| Algorithm | Time Complexity | Space Complexity | Notes |
|-----------|----------------|------------------|-------|
| FFT Convolution | O(NÂ² log N) | O(NÂ²) | Dominant operation |
| Richardson-Lucy | O(I Â· NÂ² log N) | O(NÂ²) | I = iterations (60-200) |
| Wiener Filter | O(NÂ² log N) | O(NÂ²) | Single pass |
| BM3D Denoising | O(NÂ² log N) | O(NÂ²) | Highly optimized |
| PSF Estimation | O(NÂ² log N + NÎ¸) | O(NÂ²) | Î¸ = 90 angles |
| PSNR/SSIM | O(NÂ²) | O(NÂ²) | Linear scan |

### Memory Usage

| Component | Memory Footprint |
|-----------|-----------------|
| Input Image (512Ã—512Ã—3) | ~0.75 MB |
| Intermediate Results | ~3 MB |
| FFT Buffers | ~2 MB |
| PSF Analysis | ~1 MB |
| **Peak Usage** | **~7 MB** |

### Optimization Techniques

1. **FFT-based Convolution**
   - 25Ã— faster than spatial convolution
   - Efficient for large kernels

2. **Luminance-Only Processing**
   - Process Y channel only in YCbCr space
   - 3Ã— faster than RGB processing
   - Minimal quality loss

3. **Adaptive Algorithm Selection**
   - Skip denoising when noise level < 0.1
   - Use Wiener only for blur severity < 0.7
   - Prevents unnecessary computation

4. **Vectorization**
   - NumPy operations instead of Python loops
   - SIMD acceleration where available

---

## ğŸ“š API Reference

### Main Function

```python
def restore_image_with_degradation_awareness(
    img_rgb: np.ndarray,
    params: Dict[str, Any]
) -> Dict[str, Any]:
    """
    Complete restoration pipeline with adaptive processing.
    
    Parameters
    ----------
    img_rgb : np.ndarray
        Input RGB image, shape (H, W, 3), dtype float32, range [0, 1]
        
    params : dict
        Processing parameters:
        - NOISE_SIGMA: float [5.0-25.0] - Noise std deviation
        - WIENER_BAL: float [0.001-0.1] - Wiener regularization
        - RL_ITERS: int [30-200] - Richardson-Lucy iterations
        - TV_WEIGHT: float [0.001-0.05] - TV regularization
        - UNSHARP_AMOUNT: float [0.1-1.0] - Sharpening strength
        - USE_BM3D: bool - Use BM3D denoising if available
        - AUTO_ADAPT: bool - Enable auto parameter adaptation
    
    Returns
    -------
    dict
        Results containing:
        - 'input': Original input image
        - 'degradation_info': Degradation profile
        - 'denoised': Denoised image (if applied)
        - 'wiener': Wiener deconvolution result
        - 'deblurred': Final deblurred image
        - 'final': Final restored image
        - 'psf': Estimated PSF kernel
        - 'psf_len': Blur length in pixels
        - 'psf_ang': Blur angle in degrees
        - 'deblur_method': Method used
    
    Examples
    --------
    >>> from PIL import Image
    >>> img = np.array(Image.open("blurry.jpg")).astype(np.float32) / 255.0
    >>> params = {'NOISE_SIGMA': 12.0, 'WIENER_BAL': 0.01, 
    ...           'RL_ITERS': 100, 'AUTO_ADAPT': True}
    >>> results = restore_image_with_degradation_awareness(img, params)
    >>> restored = results['final']
    """
```

### Helper Functions

```python
def estimate_motion_psf_robust(
    image_gray: np.ndarray,
    max_len: int = 120
) -> Tuple[np.ndarray, float, float]:
    """
    Robust PSF estimation using Radon + Cepstrum.
    
    Returns: (psf, length, angle)
    """

def compute_comprehensive_metrics(
    gt_rgb: np.ndarray,
    input_rgb: np.ndarray,
    restored_rgb: np.ndarray
) -> Dict[str, float]:
    """
    Compute quality metrics: PSNR, SSIM, MSE, Sharpness.
    
    Returns: dict with input, final, and improvement values
    """
```

---

## ğŸ¤ Contributing

We welcome contributions! Here's how:

### Ways to Contribute

1. **ğŸ› Report Bugs**
   - Use [GitHub Issues](https://github.com/yourusername/visionrestore-pro/issues)
   - Include steps to reproduce
   - Provide system information

2. **ğŸ’¡ Suggest Features**
   - Open a feature request
   - Describe use case
   - Discuss implementation

3. **ğŸ”§ Submit Code**
   - Fork repository
   - Create feature branch
   - Write tests
   - Submit pull request

### Development Setup

```bash
# Clone your fork
git clone https://github.com/yourusername/visionrestore-pro.git
cd visionrestore-pro

# Create environment
python -m venv venv
source venv/bin/activate

# Install dev dependencies
pip install -r requirements-dev.txt

# Run tests
pytest tests/ -v

# Run linters
flake8 src/
black src/ --check
```

### Code Style

- Follow PEP 8
- Use type hints
- Write docstrings (NumPy format)
- Add tests for new features
- Comment complex algorithms

---

## ğŸ“„ License

This project is licensed under the **MIT License**.

```
MIT License

Copyright (c) 2024 VisionRestore Pro

Permission is hereby granted, free of charge, to any person obtaining a copy
of this software and associated documentation files (the "Software"), to deal
in the Software without restriction, including without limitation the rights
to use, copy, modify, merge, publish, distribute, sublicense, and/or sell
copies of the Software, and to permit persons to whom the Software is
furnished to do so, subject to the following conditions:

The above copyright notice and this permission notice shall be included in all
copies or substantial portions of the Software.

THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT.
```

See [LICENSE](LICENSE) file for full details.

---

## ğŸ™ Acknowledgments

### Research & Algorithms

This work implements algorithms from:

1. **Richardson-Lucy Algorithm**
   - Richardson, W. H. (1972). "Bayesian-Based Iterative Method of Image Restoration"
   - Lucy, L. B. (1974). "An iterative technique for the rectification of observed distributions"

2. **BM3D Denoising**
   - Dabov, K., et al. (2007). "Image Denoising by Sparse 3-D Transform-Domain Collaborative Filtering"

3. **Total Variation**
   - Rudin, L., Osher, S., & Fatemi, E. (1992). "Nonlinear total variation based noise removal algorithms"

4. **SSIM Metric**
   - Wang, Z., et al. (2004). "Image Quality Assessment: From Error Visibility to Structural Similarity"

### Libraries & Tools

- **Streamlit** - Web application framework
- **NumPy** - Numerical computing
- **OpenCV** - Computer vision
- **scikit-image** - Image processing
- **SciPy** - Scientific computing
- **Matplotlib** - Visualization



[â¬† Back to Top](#-visionrestore-pro)

</div>
